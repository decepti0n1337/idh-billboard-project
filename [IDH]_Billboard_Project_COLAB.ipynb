{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Cc8hFL6a0-yx",
        "HXzmsfoj1N3x",
        "HVUDLSs90rio",
        "vZLRcyvl1Ezl",
        "LAgdRb7h8Ecy",
        "9OOACv89Q03K",
        "wA6ebBWCSN5D",
        "-h4M0t9n9RhR",
        "EuhXQI9z06vE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc8hFL6a0-yx"
      },
      "source": [
        "# RUN THESE (please check which code block needs to run at which time)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phpeLvAVQjcS"
      },
      "source": [
        "## Import modules. (Run this first)\n",
        "\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from itertools import dropwhile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpVm7cXHsTto"
      },
      "source": [
        "## Download necesssary files for get lyrics process. (Do this before get lyrics process)\n",
        "\n",
        "!gdown --id 1JVE5IXhm_vJtSeXOyqdhV4vGn2v45nyK\n",
        "!gdown --id 1HaWhulAfzIlCee6zG4tHZ8v0EnWmddXF\n",
        "!gdown --id 1PQ99CYciRhNu0rAtDJ0wfcbg5XeYjntF\n",
        "!gdown --id 1-BZFtKJA-QUEbWf5EVRMuggE9-GStiMP\n",
        "!gdown --id 1UfybC3eagnMQcGjy5mSLB_oK33MmW0aB\n",
        "!gdown --id 15In_8r4GN8sbo8s-Y8JJK3aYO-f4Chx9\n",
        "!gdown --id 10zqGqoQopC43dr7qI7pDwY916SmrCnoN\n",
        "!gdown --id 1DSiY4P4z_eUdI59SzHQKuQZnpXLSigfY\n",
        "!gdown --id 1qbSX486vx1Mzn8NGUBpGmfhTKcYg8236\n",
        "!gdown --id 1eDpIrV_RsHA5CZl3TaexE5dW980i4c3Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwAWpFaB8lJs"
      },
      "source": [
        "## Download necesssary files for word freq process. (Do this before word freq process, but after get lyrics process)\n",
        "\n",
        "!gdown --id 1AbDp9l_o50P_QSezO_-3A5_Loigl_qZw\n",
        "!gdown --id 136UHUkrbxa0I_0Q9k9fzQ6KDCT17fmLF\n",
        "!gdown --id 12-rYWw3feJ8dQq5wTRRXPHW989J-sLK5\n",
        "!gdown --id 16WkTXzPKkJqjcY_Rcxm3Rs9Dh10LOV5y\n",
        "!gdown --id 143PlOydeEkb4YCh5HZTfy8qCzFPAJoMx\n",
        "!gdown --id 1WYaA7A52G__UnxgRsnDl6X7mI3fIhBHm\n",
        "!gdown --id 1JxGxyLl5O9t2y47T8BtLFiIwQ1ZpPaPK\n",
        "!gdown --id 12VpjTDKBfyUxiw30EuOuKnL-s2B6pwKz\n",
        "!gdown --id 18zs155H59XoTqs1E_Ig7J3rr5F6RuPob\n",
        "!gdown --id 1EyVumZQC5xPCSGn5bg--Ou0HG5ugd6Eo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zRalkMhRCpL"
      },
      "source": [
        "## Download necesssary files for ethnicity data process. (Do this before ethnicity data process)\n",
        "\n",
        "!gdown --id 1sugX0y7FuQ_wvOFblBPkrZjDY4970aVk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8fxyC1qw_n1"
      },
      "source": [
        "## Download necesssary files for concatenation process. (Do this before concatenation process)\n",
        "\n",
        "!gdown --id 1_VW4mS36rDqFzmNa8hc7yZ5lVCuhAGjp\n",
        "!gdown --id 13aTyaQo-6d3RGewEAVVgG6yyZb_oNmvu\n",
        "!gdown --id 1ixLeAdffbfW8sKh6-NpiSRYmuXCmJ7LU\n",
        "!gdown --id 1yc5AizxgVE0FAU16FrYkE-qJYMKMz8RY\n",
        "!gdown --id 1jA6MSY1c0gQ4e0APu32pO8gzrgw03jaW\n",
        "!gdown --id 1Ew3L5E2DuTqqiXRs4jWiyOGJTAMGYB9J\n",
        "!gdown --id 1hsMFdiJfNHzR9LixIqsHN4-ZzT8aNgLC\n",
        "!gdown --id 12BSO2yn4uoMS2SjcWMVfAkTzA_RJit43\n",
        "!gdown --id 1dh9QqAE6-PqwBxPyN3pIXnpzRQF6gPMZ\n",
        "!gdown --id 1z26GrH87bC-_DKdabLTli7eH3hgj73DJ\n",
        "\n",
        "!gdown --id 1IxcPpFZbU_U5zQSGD5GqepCnBjGX4_0J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXzmsfoj1N3x"
      },
      "source": [
        "# APISEEDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzpNuxmq0TjA"
      },
      "source": [
        "## APISEEDS API\n",
        "\n",
        "## Lyrics endpoint\n",
        "endpoint = 'https://orion.apiseeds.com/api/music/lyric/'\n",
        "\n",
        "## Remember to run API KEY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVUDLSs90rio"
      },
      "source": [
        "# API KEY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO5gR1qn0fDs"
      },
      "source": [
        "## API KEY TOP SECRET DO NOT LEAK.\n",
        "\n",
        "## deleted api key for security purposes.\n",
        "## please request free API key from APISEEDS\n",
        "## https://apiseeds.com/\n",
        "\n",
        "api = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZLRcyvl1Ezl"
      },
      "source": [
        "# GET LYRICS PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfMgQw1Qy2O"
      },
      "source": [
        "## Read datas.\n",
        "## No encoding works, but unicode_escape works for some reason. Don't ask me why.\n",
        "\n",
        "data_2010 = pd.read_csv('billboard-2010.csv', encoding= 'unicode_escape')\n",
        "data_2011 = pd.read_csv('billboard-2011.csv', encoding= 'unicode_escape')\n",
        "data_2012 = pd.read_csv('billboard-2012.csv', encoding= 'unicode_escape')\n",
        "data_2013 = pd.read_csv('billboard-2013.csv', encoding= 'unicode_escape')\n",
        "data_2014 = pd.read_csv('billboard-2014.csv', encoding= 'unicode_escape')\n",
        "data_2015 = pd.read_csv('billboard-2015.csv', encoding= 'unicode_escape')\n",
        "data_2016 = pd.read_csv('billboard-2016.csv', encoding= 'unicode_escape')\n",
        "data_2017 = pd.read_csv('billboard-2017.csv', encoding= 'unicode_escape')\n",
        "data_2018 = pd.read_csv('billboard-2018.csv', encoding= 'unicode_escape')\n",
        "data_2019 = pd.read_csv('billboard-2019.csv', encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6a05oQooOLa"
      },
      "source": [
        "## All data variables, used for iterating loops.\n",
        "\n",
        "datanames = [data_2010, data_2011, data_2012, data_2013, data_2014, data_2015, data_2016, data_2017, data_2018, data_2019]\n",
        "datanames_str = ['data_2010', 'data_2011', 'data_2012', 'data_2013', 'data_2014', 'data_2015', 'data_2016', 'data_2017', 'data_2018', 'data_2019']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmS7u03vsDJI"
      },
      "source": [
        "## Clean artists data from bad encoding.\n",
        "\n",
        "## loop to all datas.\n",
        "for data in datanames:\n",
        "  artists = data['Artist(s)'].to_list()\n",
        "  titles = data['Title'].to_list()\n",
        "\n",
        "  ## empty list for cleaned datas.\n",
        "  cleanartists = []\n",
        "  cleantitles = []\n",
        "\n",
        "  ## loop into each artists in the data.\n",
        "  for artist in artists:\n",
        "\n",
        "    ## cleaning process.\n",
        "    clean1artist = artist.replace('Â', '')\n",
        "    clean2artist = clean1artist.replace('\\xa0', ' ')\n",
        "    clean3artist = clean2artist.replace('â', '')\n",
        "    clean4artist = clean3artist.replace('\\x93', '')\n",
        "    clean5artist = clean4artist.replace('\\x98', '')\n",
        "    clean6artist = clean5artist.strip()\n",
        "\n",
        "    ## put into empty list.\n",
        "    cleanartists.append(clean5artist)\n",
        "\n",
        "  ## loop into each titles in the data.\n",
        "  for title in titles:\n",
        "\n",
        "    ## cleaning process.\n",
        "    clean1title = title.replace('Â', '')\n",
        "    clean2title = clean1title.replace('\\xa0', ' ')\n",
        "    clean3title = clean2title.replace('â', '')\n",
        "    clean4title = clean3title.replace('\\x93', '')\n",
        "    clean5title = clean4title.replace('\\x98', '')\n",
        "    clean6title = clean5title.strip()\n",
        "\n",
        "    ## put into empty list.\n",
        "    cleantitles.append(clean5title)\n",
        "\n",
        "  ## put cleaned data back into data.\n",
        "  data['Artist(s)'] = cleanartists\n",
        "  data['Title'] = cleantitles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KXF9E413Kl5"
      },
      "source": [
        "## Define relevant artist function\n",
        "\n",
        "def relevantartist(word):\n",
        "\n",
        "  ## generate relevant artist algorithm.\n",
        "  regex= re.compile(r'^\\S+')\n",
        "\n",
        "  ## check if word matches algorithm\n",
        "  match = re.match(regex, word)\n",
        "\n",
        "  ## get relevant artist\n",
        "  if match is not None:\n",
        "    return(match.group(0))\n",
        "  else:\n",
        "    return(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaL4fYTLx9pV"
      },
      "source": [
        "## Define relevant title function\n",
        "\n",
        "def relevanttitle(word):\n",
        "  ## generate relevant titles algorithm.\n",
        "  regex= re.compile(r'\\s?\\(.+\\)')\n",
        "\n",
        "  ## get rid of unrelevant title bits (strings in brackets)\n",
        "  sub = re.sub(regex, '', word)\n",
        "\n",
        "  ## get relevant title\n",
        "  if sub is not None:\n",
        "    return(sub)\n",
        "  else:\n",
        "    return(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOBy0bpswCLw"
      },
      "source": [
        "## Generate relevant artist.\n",
        "\n",
        "## loop to all datas.\n",
        "for data in datanames:\n",
        "  artists = data['Artist(s)'].to_list()\n",
        "  titles = data['Title'].to_list()\n",
        "\n",
        "  ## empty list for relevant search terms\n",
        "  relevantartists = []\n",
        "  relevanttitles = []\n",
        "\n",
        "  ## generate relevant search terms\n",
        "  for artist in artists:\n",
        "    relevantartists.append(relevantartist(artist))\n",
        "  for title in titles:\n",
        "    relevanttitles.append(relevanttitle(title))\n",
        "\n",
        "  ## add new column to data\n",
        "  data['relevantArtist'] = relevantartists\n",
        "  data['relevantTitle'] = relevanttitles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZnbYzsQ4jte"
      },
      "source": [
        "## Get lyrics\n",
        "\n",
        "## loop to all datas.\n",
        "for data in datanames:\n",
        "  artists = data['relevantArtist'].to_list()\n",
        "  titles = data['relevantTitle'].to_list()\n",
        "\n",
        "  ## empty list for lyrics\n",
        "  lyrics = []\n",
        "\n",
        "  ## 90-sec timer delay per data group (bypassing 100 call limit per minute)\n",
        "  time.sleep(90)\n",
        "\n",
        "  ## search for lyrics using API\n",
        "  for artist, title in zip(artists, titles):\n",
        "    url = endpoint + artist + '/' + title + '?apikey=' + api\n",
        "    response = requests.get(url)\n",
        "\n",
        "    ## convert JSON to dict\n",
        "    try:\n",
        "      search_dict = json.loads(response.text)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    ## put into empty list\n",
        "    try:\n",
        "      lyrics.append(search_dict['result']['track']['text'])\n",
        "    except:\n",
        "      lyrics.append('')\n",
        "\n",
        "  ## add new column to data\n",
        "  data['lyrics'] = lyrics\n",
        "\n",
        "  ## clean line feed (\\n) and carriage return (\\r)\n",
        "  data['lyrics'] = data['lyrics'].apply(lambda x: x.replace('\\n', ' '))\n",
        "  data['lyrics'] = data['lyrics'].apply(lambda x: x.replace('\\r', ' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAgdRb7h8Ecy"
      },
      "source": [
        "# WORD FREQ PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyDeyQV38KUE"
      },
      "source": [
        "## Read datas.\n",
        "## No encoding works, but unicode_escape works for some reason. Don't ask me why.\n",
        "\n",
        "lyrics_2010 = pd.read_csv('data_2010_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2011 = pd.read_csv('data_2011_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2012 = pd.read_csv('data_2012_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2013 = pd.read_csv('data_2013_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2014 = pd.read_csv('data_2014_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2015 = pd.read_csv('data_2015_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2016 = pd.read_csv('data_2016_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2017 = pd.read_csv('data_2017_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2018 = pd.read_csv('data_2018_lyrics.csv', encoding= 'unicode_escape')\n",
        "lyrics_2019 = pd.read_csv('data_2019_lyrics.csv', encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVyZSI5H9php"
      },
      "source": [
        "## All data variables, used for iterating loops.\n",
        "\n",
        "lyricsnames = [lyrics_2010, lyrics_2011, lyrics_2012, lyrics_2013, lyrics_2014, lyrics_2015, lyrics_2016, lyrics_2017, lyrics_2018, lyrics_2019]\n",
        "lyricsnames_str = ['lyrics_2010', 'lyrics_2011', 'lyrics_2012', 'lyrics_2013', 'lyrics_2014', 'lyrics_2015', 'lyrics_2016', 'lyrics_2017', 'lyrics_2018', 'lyrics_2019']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab0suhmi-Icj"
      },
      "source": [
        "## Tokenize lyrics\n",
        "\n",
        "## setting up spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "## loop into all datas\n",
        "for data in lyricsnames:\n",
        "  lyrics =  data['lyrics'].to_list()\n",
        "\n",
        "  ## empty list waiting to be appended\n",
        "  lyricsToken_list = []\n",
        "\n",
        "  ## iterated into all lyrics\n",
        "  for lyric in tqdm(lyrics):\n",
        "    lyricsToken = []\n",
        "    doc = nlp(lyric)\n",
        "\n",
        "    ## tokenized\n",
        "    for token in doc:\n",
        "      lyricsToken.append(str(token).lower())\n",
        "\n",
        "    ## append into empty list\n",
        "    lyricsToken_list.append(lyricsToken)\n",
        "\n",
        "  ## put list into data\n",
        "  data['lyricsToken'] = lyricsToken_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTPBmWiuEIPb"
      },
      "source": [
        "## Counting tokens.\n",
        "\n",
        "## loop into all datas\n",
        "for data in lyricsnames:\n",
        "  lyricsToken =  data['lyricsToken'].to_list()\n",
        "\n",
        "  ## empty list waiting to be appended\n",
        "  tokenCount = []\n",
        "\n",
        "  ## iterated into all tokens\n",
        "  for tokens in lyricsToken:\n",
        "    counter = Counter(tokens)\n",
        "\n",
        "## Set threshold = 6 (if less than 6, delete it.)\n",
        "    for key, count in dropwhile(lambda key_count: key_count[1] > 5, counter.most_common()): ## thanks, stackoverflow.\n",
        "      del counter[key]\n",
        "\n",
        "    ## append into empty list\n",
        "    tokenCount.append(counter.most_common())\n",
        "\n",
        "  ## put list into data\n",
        "  data['tokenCount'] = tokenCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJMSldriHPim"
      },
      "source": [
        "## Delete irrelevant columns.\n",
        "\n",
        "for data in lyricsnames:\n",
        "  del data['relevantArtist']\n",
        "  del data['relevantTitle']\n",
        "  del data['lyricsToken']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OOACv89Q03K"
      },
      "source": [
        "# ETHNICITY DATA PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-FF89HGQ0ST"
      },
      "source": [
        "## Read datas.\n",
        "## No encoding works, but unicode_escape works for some reason. Don't ask me why.\n",
        "\n",
        "data_ethnicity = pd.read_csv('ethnicity.csv', encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kDNWA_eRZwo"
      },
      "source": [
        "## Make into list\n",
        "\n",
        "data_ethnicity['Ethnicity'] = data_ethnicity['Ethnicity'].apply(lambda x: x.split(' , '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUip-rkP3qOE"
      },
      "source": [
        "## Clean datas\n",
        "\n",
        "for data in data_ethnicity['Ethnicity'].to_list():\n",
        "  for elem in data:\n",
        "    elem.strip()\n",
        "\n",
        "## empty list waiting to be appended\n",
        "cleanartists = []\n",
        "\n",
        "## loop into all artists\n",
        "for artist in data_ethnicity['Artist'].to_list():\n",
        "\n",
        "  ## cleaning process\n",
        "  clean1artist = artist.replace('Â', '')\n",
        "  clean2artist = clean1artist.replace('\\xa0', ' ')\n",
        "  clean3artist = clean2artist.replace('â', '')\n",
        "  clean4artist = clean3artist.replace('\\x93', '')\n",
        "  clean5artist = clean4artist.replace('\\x98', '')\n",
        "  clean6artist = clean5artist.replace('\\x83', '')\n",
        "  clean7artist = clean6artist.replace('\\x92', '')\n",
        "  clean8artist = clean7artist.replace('Ã', '')\n",
        "  clean9artist = clean8artist.replace('\\x82', '')\n",
        "  clean10artist = clean9artist.replace('©', '')\n",
        "  clean11artist = clean10artist.replace('é', '')\n",
        "  clean12artist = clean11artist.replace('³', '')\n",
        "  clean13artist = clean12artist.replace('\\xad', '')\n",
        "  clean14artist = clean13artist.replace(' \\x80', '')\n",
        "  clean15artist = clean14artist.strip()\n",
        "\n",
        "  ## append into empty list\n",
        "  cleanartists.append(clean15artist)\n",
        "\n",
        "## put list into data\n",
        "data_ethnicity['Artist'] = cleanartists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA6ebBWCSN5D"
      },
      "source": [
        "# CONCATENATE PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyTEZc-wRlQB"
      },
      "source": [
        "## Read datas.\n",
        "## No encoding works, but unicode_escape works for some reason. Don't ask me why.\n",
        "\n",
        "## ignore this next line, using old data from ethnicity data process instead.\n",
        "## data_ethnicity = pd.read_csv('ethnicity-normalised.csv', encoding= 'unicode_escape')\n",
        "\n",
        "wordfreq_2010 = pd.read_csv('lyrics_2010_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2011 = pd.read_csv('lyrics_2011_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2012 = pd.read_csv('lyrics_2012_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2013 = pd.read_csv('lyrics_2013_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2014 = pd.read_csv('lyrics_2014_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2015 = pd.read_csv('lyrics_2015_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2016 = pd.read_csv('lyrics_2016_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2017 = pd.read_csv('lyrics_2017_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2018 = pd.read_csv('lyrics_2018_word-freq.csv', encoding= 'unicode_escape')\n",
        "wordfreq_2019 = pd.read_csv('lyrics_2019_word-freq.csv', encoding= 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfj6h4EdzRoR"
      },
      "source": [
        "## All data variables, used for iterating loops.\n",
        "\n",
        "wordfreqnames = [wordfreq_2010, wordfreq_2011, wordfreq_2012, wordfreq_2013, wordfreq_2014, wordfreq_2015, wordfreq_2016, wordfreq_2017, wordfreq_2018, wordfreq_2019]\n",
        "wordfreqnames_str = ['wordfreq_2010', 'wordfreq_2011', 'wordfreq_2012', 'wordfreq_2013', 'wordfreq_2014', 'wordfreq_2015', 'wordfreq_2016', 'wordfreq_2017', 'wordfreq_2018', 'wordfreq_2019']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBf3iLhczf6A"
      },
      "source": [
        "## Clean artists data from bad encoding.\n",
        "\n",
        "## loop to all datas.\n",
        "for wordfreq in wordfreqnames:\n",
        "  artists = wordfreq['Artist(s)'].to_list()\n",
        "  titles = wordfreq['Title'].to_list()\n",
        "\n",
        "  ## empty list for cleaned datas.\n",
        "  cleanartists = []\n",
        "  cleantitles = []\n",
        "\n",
        "  ## loop into each artists in the data.\n",
        "  for artist in artists:\n",
        "\n",
        "    ## cleaning process.\n",
        "    clean1artist = artist.replace('Â', '')\n",
        "    clean2artist = clean1artist.replace('\\xa0', ' ')\n",
        "    clean3artist = clean2artist.replace('â', '')\n",
        "    clean4artist = clean3artist.replace('\\x93', '')\n",
        "    clean5artist = clean4artist.replace('\\x98', '')\n",
        "    clean6artist = clean5artist.replace('\\x83', '')\n",
        "    clean7artist = clean6artist.replace('\\x92', '')\n",
        "    clean8artist = clean7artist.replace('Ã', '')\n",
        "    clean9artist = clean8artist.replace('\\x82', '')\n",
        "    clean10artist = clean9artist.replace('©', '')\n",
        "    clean11artist = clean10artist.replace('é', '')\n",
        "    clean12artist = clean11artist.replace('³', '')\n",
        "    clean13artist = clean12artist.replace('\\xad', '')\n",
        "    clean14artist = clean13artist.replace(' \\x80', '')\n",
        "    clean15artist = clean14artist.strip()\n",
        "\n",
        "    ## put into empty list.\n",
        "    cleanartists.append(clean15artist)\n",
        "\n",
        "  ## loop into each titles in the data.\n",
        "  for title in titles:\n",
        "\n",
        "    ## cleaning process.\n",
        "    clean1title = title.replace('Â', '')\n",
        "    clean2title = clean1title.replace('\\xa0', ' ')\n",
        "    clean3title = clean2title.replace('â', '')\n",
        "    clean4title = clean3title.replace('\\x93', '')\n",
        "    clean5title = clean4title.replace('\\x98', '')\n",
        "    clean6title = clean5title.replace('\\x83', '')\n",
        "    clean7title = clean6title.replace('\\x92', '')\n",
        "    clean8title = clean7title.replace('Ã', '')\n",
        "    clean9title = clean8title.replace('\\x82', '')\n",
        "    clean10title = clean9title.replace('©', '')\n",
        "    clean11title = clean10title.strip()\n",
        "\n",
        "    ## put into empty list.\n",
        "    cleantitles.append(clean11title)\n",
        "\n",
        "  ## put cleaned data back into data.\n",
        "  wordfreq['Artist(s)'] = cleanartists\n",
        "  wordfreq['Title'] = cleantitles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Dnn37v0FRV"
      },
      "source": [
        "## Make a string of artists separated with commas to easiliy read out that how many artists are there in each song.\n",
        "\n",
        "## loop to all datas.\n",
        "for wordfreq in wordfreqnames:\n",
        "  artists = wordfreq['Artist(s)'].to_list()\n",
        "\n",
        "  ## empty list waiting to be appended\n",
        "  artist_list=[]\n",
        "\n",
        "  ## regex algorithm\n",
        "  re_feat = re.compile(r'\\sfeaturing')\n",
        "  re_and = re.compile(r'\\sand')\n",
        "  re_ampersand = re.compile(r'\\s&')\n",
        "  re_plus = re.compile(r'\\s\\+')\n",
        "\n",
        "  ## loop into each artists in the data.\n",
        "  for artist in artists:\n",
        "\n",
        "    ## separate artist with commas\n",
        "    artist1clean = re.sub(re_feat,',',artist)\n",
        "    artist2clean = re.sub(re_and,',',artist1clean)\n",
        "    artist3clean = re.sub(re_ampersand,',',artist2clean)\n",
        "    artist4clean = re.sub(re_plus,',',artist3clean)\n",
        "    artist5clean = artist4clean.strip()\n",
        "\n",
        "    ## appended into empty list\n",
        "    artist_list.append(artist5clean)\n",
        "\n",
        "  ## put list into data\n",
        "  wordfreq['Artistlist'] = artist_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pMnDV1P9A57"
      },
      "source": [
        "## Turn artists separated with commas into list of artists.\n",
        "\n",
        "## loop into all datas\n",
        "for wordfreq in wordfreqnames:\n",
        "\n",
        "  ## split with comma\n",
        "  wordfreq['Artistlist'] = wordfreq['Artistlist'].apply(lambda x: x.split(','))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXTg2AGf3fLi"
      },
      "source": [
        "## Make an list consists of artist and ethnicity for cross-checking data\n",
        "\n",
        "## empty list waiting to be appended\n",
        "artistethnic = []\n",
        "\n",
        "## loop into ethnicity data\n",
        "for artist, ethnicity in zip(data_ethnicity['Artist'].to_list(), data_ethnicity['Ethnicity'].to_list()):\n",
        "\n",
        "  ## append into empty list\n",
        "  artistethnic.append([artist, ethnicity])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2m4r-xGAo7N"
      },
      "source": [
        "## Cross-check ethnicity data with wordfreq data.\n",
        "\n",
        "## loop into all wordfreq datas\n",
        "for wordfreq in wordfreqnames:\n",
        "\n",
        "  ## empty list (1) waiting to be appended\n",
        "  ethnicities_list = []\n",
        "\n",
        "  ## loop into each list of artists\n",
        "  for artists in wordfreq['Artistlist'].to_list():\n",
        "\n",
        "    ## empty list (2) waiting to be appended\n",
        "    ethnicities = []\n",
        "\n",
        "    ## loop into each artist\n",
        "    for artist in artists:\n",
        "\n",
        "      ## loop into ethnicity data\n",
        "      for elem in artistethnic:\n",
        "\n",
        "        ## check whether ethnicity data has that artist\n",
        "        if elem[0] in artist:\n",
        "\n",
        "          ## append into empty list (2)\n",
        "          ethnicities.append(elem[1])\n",
        "\n",
        "    ## append into empty list (1)\n",
        "    ethnicities_list.append(ethnicities)\n",
        "\n",
        "  ## put list into data\n",
        "  wordfreq['ethnicity'] = ethnicities_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzYOzAzXFh7I"
      },
      "source": [
        "## Test whether data is loss and needs to be checked.\n",
        "\n",
        "## loop into all datas\n",
        "for wordfreq in wordfreqnames:\n",
        "  Artistlist = wordfreq['Artistlist'].to_list()\n",
        "  ethnicity = wordfreq['ethnicity'].to_list()\n",
        "\n",
        "  ## empty list waiting to be appended\n",
        "  needsCheck = []\n",
        "\n",
        "  ## loop into each artist and ethnicity\n",
        "  for artist, ethnic in zip(Artistlist, ethnicity):\n",
        "\n",
        "    ## check whether data is not loss\n",
        "    if len(artist) == len(ethnic):\n",
        "      needsCheck.append('False')\n",
        "    else:\n",
        "      needsCheck.append('True')\n",
        "\n",
        "  ## put list into data\n",
        "  wordfreq['needsCheck'] = needsCheck\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTjubPBIDE4V"
      },
      "source": [
        "## Delete irrelevant data.\n",
        "\n",
        "for wordfreq in wordfreqnames:\n",
        "  del wordfreq['Artistlist']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h4M0t9n9RhR"
      },
      "source": [
        "# EXPORT (no need to use during playground)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knccss_q9UTM"
      },
      "source": [
        "## Export lyrics data.\n",
        "\n",
        "for data, data_str in zip(datanames, datanames_str):\n",
        "  data.to_csv( data_str +'_lyrics.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-UGCsq-G5gH"
      },
      "source": [
        "## Export word freq data.\n",
        "\n",
        "for lyrics, lyrics_str in zip(lyricsnames, lyricsnames_str):\n",
        "  lyrics.to_csv( lyrics_str +'_word-freq.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6aS2Uf4TK76"
      },
      "source": [
        "## Export ethnicity data.\n",
        "\n",
        "data_ethnicity.to_csv('ethnicity-normalised.csv', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC-NrTMNDSN8"
      },
      "source": [
        "## Export concatenated data.\n",
        "\n",
        "for wordfreq, wordfreq_str in zip(wordfreqnames, wordfreqnames_str):\n",
        "  wordfreq.to_csv(wordfreq_str +'_concat.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuhXQI9z06vE"
      },
      "source": [
        "# TEST PLAYGROUND (there's nothing important here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OrvxOLJ1RTZ"
      },
      "source": [
        "## Test\n",
        "data_2011['lyrics'] = data_2011['lyrics'].apply(lambda x: x.replace('\\n', ' '))\n",
        "data_2011['lyrics'] = data_2011['lyrics'].apply(lambda x: x.replace('\\r', ' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AVZNdavB8-m",
        "outputId": "cf87f9fe-47f4-434e-ba9a-19e81c88d304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "data_2010"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c98b80aefa4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_2010\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_2010' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyZWgx3n6jZI"
      },
      "source": [
        "url = '' ## deleted for security purposes.\n",
        "response = requests.get(url)\n",
        "search_dict = json.loads(response.text)\n",
        "print(search_dict['result']['track']['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m0c6kyd-nAR",
        "outputId": "b6c14935-9dd8-4d31-ec1f-f28d955ae608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "lyrics_2010"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Artist(s)</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>tokenCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Tik Tok</td>\n",
              "      <td>Kesha</td>\n",
              "      <td>[Verse 1: Ke$ha &amp; P Diddy] Wake up in the morn...</td>\n",
              "      <td>[(,, 90), (the, 26), (oh, 24), (whoa, 24), (up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Need You Now</td>\n",
              "      <td>Lady Antebellum</td>\n",
              "      <td>Picture perfect memories, Scattered all around...</td>\n",
              "      <td>[(i, 33), (you, 13), (and, 12), (need, 11), (n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey, Soul Sister</td>\n",
              "      <td>Train</td>\n",
              "      <td>Hey, hey, hey Your lipstick stains On the fron...</td>\n",
              "      <td>[(you, 24), (i, 20), (hey, 19), (,, 18), ( , 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>California Gurls</td>\n",
              "      <td>Katy Perry featuring Snoop Dogg</td>\n",
              "      <td>[Intro: Snoop Dogg] Greetings, loved ones Let'...</td>\n",
              "      <td>[(oh, 88), (-, 79), (,, 49), (the, 18), (we, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>OMG</td>\n",
              "      <td>Usher featuring will.i.am</td>\n",
              "      <td>Oh my gosh  Baby let me  Did it again, so Imma...</td>\n",
              "      <td>[(,, 125), (oh, 101), ( , 55), (my, 30), (you,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Life After You</td>\n",
              "      <td>Daughtry</td>\n",
              "      <td>Ten miles from town and I just broke down Spit...</td>\n",
              "      <td>[(i, 26), (you, 23), (after, 21), (life, 17), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Smile</td>\n",
              "      <td>Uncle Kracker</td>\n",
              "      <td>[Verse] You're better than the best I'm lucky ...</td>\n",
              "      <td>[(like, 15), (you, 13), (a, 11), (me, 10), (th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>Teach Me How to Dougie</td>\n",
              "      <td>Cali Swag District</td>\n",
              "      <td>[Verse 1: Smoove] They be like, Smoove, can yo...</td>\n",
              "      <td>[(i, 29), (,, 26), (the, 22), (me, 21), (to, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>Try Sleeping with a Broken Heart</td>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>[Intro] Let's do it baby, let's do it baby Let...</td>\n",
              "      <td>[(you, 27), (i, 21), (it, 17), (to, 16), (,, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Lover, Lover</td>\n",
              "      <td>Jerrod Niemann</td>\n",
              "      <td>Well the truth Well it hurt to say I'm gonna p...</td>\n",
              "      <td>[(,, 50), (lover, 40), (no, 34), (more, 26), (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                         tokenCount\n",
              "0            0  ...  [(,, 90), (the, 26), (oh, 24), (whoa, 24), (up...\n",
              "1            1  ...  [(i, 33), (you, 13), (and, 12), (need, 11), (n...\n",
              "2            2  ...  [(you, 24), (i, 20), (hey, 19), (,, 18), ( , 1...\n",
              "3            3  ...  [(oh, 88), (-, 79), (,, 49), (the, 18), (we, 1...\n",
              "4            4  ...  [(,, 125), (oh, 101), ( , 55), (my, 30), (you,...\n",
              "..         ...  ...                                                ...\n",
              "95          95  ...  [(i, 26), (you, 23), (after, 21), (life, 17), ...\n",
              "96          96  ...  [(like, 15), (you, 13), (a, 11), (me, 10), (th...\n",
              "97          97  ...  [(i, 29), (,, 26), (the, 22), (me, 21), (to, 1...\n",
              "98          98  ...  [(you, 27), (i, 21), (it, 17), (to, 16), (,, 1...\n",
              "99          99  ...  [(,, 50), (lover, 40), (no, 34), (more, 26), (...\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vCX-Kv5Fdsd"
      },
      "source": [
        "for data in lyricsnames:\n",
        "  lyricsToken =  data['lyricsToken'].to_list()\n",
        "\n",
        "  tokenCount = []\n",
        "\n",
        "  for tokens in lyricsToken:\n",
        "    print(type(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20OtBHw5BDBw",
        "outputId": "33f564e1-3bdc-4df7-e1e2-4a9304c6cabf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "artistethnic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['21 Savage', ['American Indian or Alaska Native']],\n",
              " ['2 Chainz', ['Black or African American']],\n",
              " ['3OH!3', ['White']],\n",
              " ['50 Cent', ['Black or African American']],\n",
              " ['5 Seconds of Summer', ['White']],\n",
              " ['6ix9ine', ['American Indian or Alaska Native']],\n",
              " ['A Boogie wit da Hoodie', ['Black or African American']],\n",
              " ['Ace Hood', ['American Indian or Alaska Native']],\n",
              " ['Adam Lambert', ['White']],\n",
              " ['Adam Levine', ['White']],\n",
              " ['Adele', ['White']],\n",
              " ['Afrojack', ['American Indian or Alaska Native', 'White']],\n",
              " ['A Great Big World', ['White']],\n",
              " ['Akon', ['white']],\n",
              " ['Alessia Cara', ['White']],\n",
              " ['Alex Clare', ['White']],\n",
              " ['Alicia Keys', ['Black or African American', 'White']],\n",
              " ['Aloe Blacc', ['black']],\n",
              " ['AlunaGeorge', ['Black or African American', 'White']],\n",
              " ['American Authors', ['white']],\n",
              " ['Amin', ['Black']],\n",
              " ['Andy Grammer', ['White']],\n",
              " ['Anna Kendrick', ['white']],\n",
              " ['Anne-Marie', ['white']],\n",
              " ['Ariana Grande', ['white']],\n",
              " ['ASAP Ferg', ['Black']],\n",
              " ['ASAP Rocky', ['Black']],\n",
              " ['Ava Max', ['white']],\n",
              " ['Avicii', ['white']],\n",
              " ['Avril Lavigne', ['white']],\n",
              " ['Awolnation', ['white']],\n",
              " ['Ayo', ['Black or African American', 'White']],\n",
              " ['Baauer', ['White']],\n",
              " ['Bad Bunny', ['American Indian or Alaska Native']],\n",
              " ['Bad Meets Evil', ['Black or African American', 'White']],\n",
              " ['Bastille', ['White']],\n",
              " ['Bazzi', ['White']],\n",
              " ['Bebe Rexha', ['White']],\n",
              " ['Becky G',\n",
              "  ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Benny Blanco', ['White']],\n",
              " ['Beyonce', ['Black or African American', 'White']],\n",
              " ['Big Sean', ['Black']],\n",
              " ['Billie Eilish', ['White']],\n",
              " ['Billy Ray Cyrus', ['White']],\n",
              " ['Bipolar Sunshine', ['Black']],\n",
              " ['Birdman', ['Black']],\n",
              " ['BJ the Chicago Kid', ['Black']],\n",
              " ['Blackbear', ['White']],\n",
              " ['Blake Shelton', ['White']],\n",
              " ['Blanco Brown', ['Black']],\n",
              " ['BlocBoy JB', ['Black']],\n",
              " ['Blueface', ['Black']],\n",
              " ['B.o.B', ['Black']],\n",
              " ['Bobby Shmurda', ['Black']],\n",
              " ['Boys Like Girls', ['White']],\n",
              " ['Bradley Cooper', ['White']],\n",
              " ['Brad Paisley', ['White']],\n",
              " ['Brantley Gilbert', ['White']],\n",
              " ['Brendon Urie', ['White']],\n",
              " ['Brett Young', ['White']],\n",
              " ['Britney Spears', ['White']],\n",
              " ['Bruno Mars', ['American Indian or Alaska Native', 'Asian', 'White']],\n",
              " ['Bryson Tiller', ['Black']],\n",
              " ['Busta Rhymes', ['Black']],\n",
              " ['Calboy', ['Black']],\n",
              " ['Cali Swag District', ['Black']],\n",
              " ['Calvin Harris', ['White']],\n",
              " ['Camila Cabello', ['American Indian or Alaska Native']],\n",
              " ['Capital Cities', ['White']],\n",
              " ['Cardi B', ['American Indian or Alaska Native', 'White']],\n",
              " ['Carly Rae Jepsen', ['White']],\n",
              " ['Carrie Underwood', ['White']],\n",
              " ['Cash Out', ['Black']],\n",
              " ['Casper M¡gico', ['American Indian or Alaska Native']],\n",
              " ['Cedric Gervais', ['White']],\n",
              " ['CeeLo Green', ['Black']],\n",
              " ['Chance the Rapper', ['Black']],\n",
              " ['Charlie Puth', ['White']],\n",
              " ['Charli XCX', ['Black or African American', 'Asian', 'White']],\n",
              " ['Chase Rice', ['White']],\n",
              " ['Cheat Codes', ['White']],\n",
              " ['Cher Lloyd', ['White']],\n",
              " ['Childish Gambino', ['Black']],\n",
              " ['Chris Brown', ['Black']],\n",
              " ['Chris Stapleton', ['White']],\n",
              " ['Christina Aguilera', ['White']],\n",
              " ['Christina Perri', ['White']],\n",
              " ['Ciara', ['Black']],\n",
              " ['City Girls', ['Black']],\n",
              " ['Clean Bandit', ['White']],\n",
              " ['Cobra Starship', ['White']],\n",
              " ['Coldplay', ['White']],\n",
              " ['Cory Gunz', ['Black']],\n",
              " ['DaBaby', ['Black']],\n",
              " ['Daddy Yankee', ['American Indian or Alaska Native']],\n",
              " ['Daft Punk', ['White']],\n",
              " ['Dan', ['Asian', 'White']],\n",
              " ['Darell', ['American Indian or Alaska Native']],\n",
              " ['Darius Rucker', ['Black']],\n",
              " ['Daughtry', ['White']],\n",
              " ['David Guetta', ['White']],\n",
              " ['Daya', ['Asian', 'White']],\n",
              " ['Dean Lewis', ['White']],\n",
              " ['Demi Lovato', ['American Indian or Alaska Native', 'White']],\n",
              " ['Descemer Bueno', ['American Indian or Alaska Native']],\n",
              " ['Desiigner', ['Black']],\n",
              " ['Dev', ['American Indian or Alaska Native', 'White']],\n",
              " ['Diddy Dirty Money',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'White']],\n",
              " ['Dierks Bentley', ['White']],\n",
              " ['Diplo', ['White']],\n",
              " ['Disciples', ['Black or African American', 'White']],\n",
              " ['Disclosure', ['White']],\n",
              " ['DJ Frank E', ['White']],\n",
              " ['DJ Khaled', ['White']],\n",
              " ['DJ Snake', ['White']],\n",
              " ['DNCE', ['White']],\n",
              " ['Drake', ['Black']],\n",
              " ['DRAM', ['Black']],\n",
              " ['Dr. Dre', ['Black']],\n",
              " ['Dua Lipa', ['White']],\n",
              " ['Dustin Lynch', ['White']],\n",
              " ['E-40', ['Black']],\n",
              " ['Echosmith', ['White']],\n",
              " ['Ed Sheeran', ['White']],\n",
              " ['Edward Maya', ['White']],\n",
              " ['Eli Young Band', ['White']],\n",
              " ['Ella Henderson', ['White']],\n",
              " ['Ella Mai', ['Black or African American', 'White']],\n",
              " ['Elle King', ['White']],\n",
              " ['Ellie Goulding', ['White']],\n",
              " ['Emeli Sand', ['Black or African American', 'White']],\n",
              " ['Eminem', ['White']],\n",
              " ['Enrique Iglesias', ['American Indian or Alaska Native', 'Asian', 'White']],\n",
              " ['Eric Church', ['White']],\n",
              " ['Eric Nally', ['White']],\n",
              " ['Eric Turner', ['White']],\n",
              " ['Fabolous', ['Black,American Indian or Alaska Native']],\n",
              " ['Fall Out Boy', ['White']],\n",
              " ['Far East Movement', ['Asian']],\n",
              " ['Fat Joe', ['American Indian or Alaska Native']],\n",
              " ['Fetty Wap', ['Black']],\n",
              " ['Fifth Harmony',\n",
              "  ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Flipp Dinero', ['American Indian or Alaska Native']],\n",
              " ['Florence Welch', ['White']],\n",
              " ['Flo Rida', ['Black']],\n",
              " ['Florida Georgia Line', ['White']],\n",
              " ['Flume', ['White']],\n",
              " ['Foster the People', ['White']],\n",
              " ['Foxes', ['White']],\n",
              " ['Frank Ocean', ['Black']],\n",
              " ['French Montana', ['American Indian or Alaska Native', 'White']],\n",
              " ['Friends', ['White']],\n",
              " ['Fun', ['White']],\n",
              " ['Future', ['Black']],\n",
              " ['Gavin DeGraw', ['White']],\n",
              " ['G-Eazy', ['American Indian or Alaska Native', 'White']],\n",
              " ['Gente de Zona', ['American Indian or Alaska Native']],\n",
              " ['George Ezra', ['White']],\n",
              " ['Gnash', ['White']],\n",
              " ['GoonRock', ['Black']],\n",
              " ['Gotye', ['White']],\n",
              " ['Grace Potter', ['White']],\n",
              " ['Grandmaster Caz', ['Black']],\n",
              " ['Grey', ['White']],\n",
              " ['Gucci Mane', ['Black']],\n",
              " ['Gunna', ['American Indian or Alaska Native']],\n",
              " ['Gym Class Heroes', ['American Indian or Alaska Native', 'White']],\n",
              " ['Hailee Steinfeld', ['White']],\n",
              " ['Halsey', ['Black or African American', 'White']],\n",
              " ['Harry Styles', ['White']],\n",
              " ['Havana Brown', ['White']],\n",
              " ['Hayley Williams', ['White']],\n",
              " ['Hollis', ['Asian', 'White']],\n",
              " ['Hot Chelle Rae', ['White']],\n",
              " ['Hozier', ['White']],\n",
              " ['Hunter Hayes', ['White']],\n",
              " ['Icona Pop', ['White']],\n",
              " ['Idina Menzel', ['White']],\n",
              " ['Iggy Azalea', ['White']],\n",
              " ['ILoveMakonnen', ['Black or African American']],\n",
              " ['iLoveMemphis', ['Black or African American']],\n",
              " ['Imagine Dragons', ['White']],\n",
              " ['Infared', ['Unknown']],\n",
              " ['Iyaz', ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Jake Owen', ['White']],\n",
              " ['James Arthur', ['White']],\n",
              " ['James Bay', ['White']],\n",
              " ['James Blake', ['Black or African American', 'White']],\n",
              " ['Janelle Monáe', ['Black or African American']],\n",
              " ['Jason Aldean', ['White']],\n",
              " ['Jason Derulo',\n",
              "  ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Jason Mraz', ['White']],\n",
              " ['Jay Rock', ['Black or African American']],\n",
              " ['Jay Sean', ['Asian']],\n",
              " ['Jay-Z', ['Black or African American']],\n",
              " ['J Balvin', ['American Indian or Alaska Native']],\n",
              " ['J. Cole', ['Black or African American', 'White']],\n",
              " ['Jeezy', ['Black or African American']],\n",
              " ['Jennifer Lawrence', ['White']],\n",
              " ['Jennifer Lopez', ['American Indian or Alaska Native']],\n",
              " ['Jeremih', ['Black or African American']],\n",
              " ['Jerrod Niemann', ['White']],\n",
              " ['Jess Glynne', ['White']],\n",
              " ['Jessie J', ['White']],\n",
              " ['Jhen Aiko', ['Black or African American', 'Asian', 'White']],\n",
              " ['Jidenna', ['Black or African American', 'White']],\n",
              " ['Jimmy Buffett', ['White']],\n",
              " ['John Legend', ['Black or African American']],\n",
              " ['John Martin', ['White']],\n",
              " ['Jonas Brothers', ['White']],\n",
              " ['Jon Bellion', ['White']],\n",
              " ['Juice Wrld', ['Black or African American']],\n",
              " ['Juicy J', ['Black or African American']],\n",
              " ['Julia Michaels', ['White']],\n",
              " ['Justin Bieber', ['White']],\n",
              " ['Justin Timberlake', ['White']],\n",
              " ['Kai', ['White']],\n",
              " ['Kane Brown', ['Black or African American', 'White']],\n",
              " ['Kanye West', ['Black or African American']],\n",
              " ['Karmin', ['White']],\n",
              " ['Katy Perry', ['White']],\n",
              " ['Keith Urban', ['White']],\n",
              " ['Kelly Clarkson', ['White']],\n",
              " ['Kelly Rowland', ['Black or African American']],\n",
              " ['Kendrick Lamar', ['Black or African American']],\n",
              " ['Kenny Chesney', ['White']],\n",
              " ['Kent Jones', ['Black or African American']],\n",
              " ['Keri Hilson', ['Black or African American']],\n",
              " ['Kesha', ['White']],\n",
              " ['Kevin Gates',\n",
              "  ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Kevin McCall', ['Black or African American']],\n",
              " ['Kevin Rudolf', ['White']],\n",
              " ['Khalid', ['Black or African American']],\n",
              " ['Kid Ink', ['Black or African American']],\n",
              " ['Kiiara', ['White']],\n",
              " ['Kimbra', ['White']],\n",
              " ['Kings of Leon', ['White']],\n",
              " ['Kip Moore', ['White']],\n",
              " ['Kirko Bangz', ['American Indian or Alaska Native', 'White']],\n",
              " ['Kodak Black', ['Black or African American']],\n",
              " ['KONGOS', ['Black or African American']],\n",
              " ['Kool Moe Dee', ['Black or African American']],\n",
              " ['Kris Allen', ['White']],\n",
              " ['Kygo', ['White']],\n",
              " ['Kyla', ['Asia']],\n",
              " ['Kyle', ['Black or African American']],\n",
              " ['Lady Antebellum', ['White']],\n",
              " ['Lady Gaga', ['White']],\n",
              " ['Lana Del Rey', ['White']],\n",
              " ['La Roux', ['White']],\n",
              " ['Lauren Alaina', ['White']],\n",
              " ['Lauren Bennett', ['White']],\n",
              " ['Lauren Daigle', ['White']],\n",
              " ['Lauv', ['White']],\n",
              " ['Lee Brice', ['White']],\n",
              " ['Lewis Capaldi', ['White']],\n",
              " ['Liam Payne', ['White']],\n",
              " ['Lil Baby', ['Black or African American']],\n",
              " ['Lil Dicky', ['White']],\n",
              " ['Lil Jon', ['Black or African American']],\n",
              " ['Lil Nas X', ['Black or African American']],\n",
              " ['Lil Pump', ['American Indian or Alaska Native']],\n",
              " ['Lil Tecca', ['Black or African American']],\n",
              " ['Lil Tjay', ['White']],\n",
              " ['Lil Uzi Vert', ['Black or African American']],\n",
              " ['Lil Wayne', ['Black or African American']],\n",
              " ['Lil Yachty', ['Black or African American']],\n",
              " ['Lily Allen', ['White']],\n",
              " ['Linkin Park', ['White']],\n",
              " ['Little Big Town', ['White']],\n",
              " ['Lizzo', ['Black or African American']],\n",
              " ['Lloyd', ['Black or African American', 'White']],\n",
              " ['LMFAO', ['Black or African American', 'White']],\n",
              " ['Logic', ['Black or African American', 'White']],\n",
              " ['Lookas', ['White']],\n",
              " ['Lorde', ['White']],\n",
              " ['Ludacris',\n",
              "  ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Luis Fonsi', ['American Indian or Alaska Native']],\n",
              " ['Lukas Graham', ['White']],\n",
              " ['Luke Bryan', ['White']],\n",
              " ['Luke Combs', ['White']],\n",
              " ['Lupe Fiasco', ['Black or African American']],\n",
              " ['Machine Gun Kelly', ['White']],\n",
              " ['Macklemore', ['White']],\n",
              " ['Mac Miller', ['White']],\n",
              " ['Magic!', ['White']],\n",
              " ['Majid Jordan', ['White']],\n",
              " ['Major Lazer', ['American Indian or Alaska Native']],\n",
              " ['Maren Morris', ['White']],\n",
              " ['Mariah Carey',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'White']],\n",
              " ['Marian Hill', ['White']],\n",
              " ['Mark Ronson', ['White']],\n",
              " ['Maroon 5', ['White']],\n",
              " ['Marshmello', ['American Indian or Alaska Native', 'White']],\n",
              " ['Martin Garrix', ['White']],\n",
              " ['Mary Lambert', ['White']],\n",
              " ['Max', ['White']],\n",
              " ['Meek Mill', ['Black or African American']],\n",
              " ['Megan Thee Stallion', ['Black or African American']],\n",
              " ['Meghan Trainor', ['White']],\n",
              " ['Melle Mel', ['Black or African American']],\n",
              " ['Metro Boomin', ['Black or African American']],\n",
              " ['Michael Bubl', ['White']],\n",
              " ['Michael Jackson', ['Black or African American']],\n",
              " ['Migos', ['Black or African American']],\n",
              " ['Miguel', ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Mike Posner', ['White']],\n",
              " ['Mike WiLL Made-It', ['Black or African American']],\n",
              " ['Mikky Ekko', ['White']],\n",
              " ['Miley Cyrus', ['White']],\n",
              " ['Miranda Lambert', ['White']],\n",
              " ['MKTO', ['Black or African American', 'White']],\n",
              " ['MNEK', ['Black or African American']],\n",
              " ['MØ', ['White']],\n",
              " ['Monty', ['Black or African American']],\n",
              " ['Morgan Wallen', ['White']],\n",
              " ['Mr Hudson', ['White']],\n",
              " ['Mr Probz', ['White']],\n",
              " ['Mumford', ['White']],\n",
              " ['Murda Beatz', ['White']],\n",
              " ['Mustard', ['Black or African American']],\n",
              " ['Natalie La Rose', ['Black']],\n",
              " ['Nate Ruess', ['White']],\n",
              " ['Naughty Boy', ['Asian']],\n",
              " ['Nayer', ['American Indian or Alaska Native', 'White']],\n",
              " ['Nelly', ['Black']],\n",
              " ['Neon Hitch', ['White']],\n",
              " ['Neon Trees', ['White']],\n",
              " ['N.E.R.D', ['Black']],\n",
              " ['New Boyz', ['Black or African American']],\n",
              " ['Ne-Yo', ['Black']],\n",
              " ['NF', ['White']],\n",
              " ['Niall Horan', ['White']],\n",
              " ['Nicki Minaj',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'Asian']],\n",
              " ['Nick Jonas', ['White']],\n",
              " ['Nicky Jam', ['American Indian or Alaska Native']],\n",
              " ['Nico', ['Black or African American', 'White']],\n",
              " ['Nio Garca', ['American Indian or Alaska Native']],\n",
              " ['NLE Choppa', ['Black or African American']],\n",
              " ['Normani', ['Black or African American', 'White']],\n",
              " ['Offset', ['Black or African American']],\n",
              " ['Of Monsters', ['White']],\n",
              " ['Olivia OBrien', ['White']],\n",
              " ['Olly Murs', ['White']],\n",
              " ['Omarion', ['Black or African American']],\n",
              " ['OMI', ['Black or African American']],\n",
              " ['One Direction', ['White']],\n",
              " ['OneRepublic', ['White']],\n",
              " ['Orianthi', ['White']],\n",
              " ['O.T. Genasis', ['Black or African American']],\n",
              " ['Owl City', ['White']],\n",
              " ['Ozuna', ['American Indian or Alaska Native']],\n",
              " ['Panic! at the Disco', ['White']],\n",
              " ['Paramore', ['White']],\n",
              " ['Passenger', ['White']],\n",
              " ['Paul McCartney', ['White']],\n",
              " ['Pharrell Williams', ['Black or African American']],\n",
              " ['Phillip Phillips', ['White']],\n",
              " ['Pink', ['White']],\n",
              " ['Pinkfong', ['White']],\n",
              " ['Pistol Annies', ['White']],\n",
              " ['Pitbull', ['American Indian or Alaska Native']],\n",
              " ['Playboi Carti', ['Black or African American']],\n",
              " ['Plies', ['Black or African American']],\n",
              " ['PnB Rock', ['Black or African American']],\n",
              " ['Polo G', ['Black or African American']],\n",
              " ['Portugal. The Man', ['White']],\n",
              " ['Post Malone', ['White']],\n",
              " ['Psy', ['Asian']],\n",
              " ['Pusha T', ['Black or African American']],\n",
              " ['Quavo', ['Black or African American']],\n",
              " ['Rachel Platten', ['White']],\n",
              " ['Rae Sremmurd', ['Black or African American']],\n",
              " ['Randy Houser', ['White']],\n",
              " ['Ray Dalton', ['Black or African American']],\n",
              " ['Ray J', ['Black or African American']],\n",
              " ['R. City', ['Black or African American']],\n",
              " ['Remy Boyz', ['Black or African American']],\n",
              " ['Remy Ma', ['Black or African American']],\n",
              " ['Rich Homie Quan', ['Black or African American']],\n",
              " ['Rich the Kid', ['Black or African American']],\n",
              " ['Rick Ross', ['Black or African American']],\n",
              " ['Rihanna',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'White']],\n",
              " ['Rita Ora', ['White']],\n",
              " ['Rivers Cuomo', ['White']],\n",
              " ['Rixton', ['White']],\n",
              " ['R. Kelly', ['Black or African American']],\n",
              " ['Robin Thicke', ['White']],\n",
              " ['Rocko', ['Black or African American']],\n",
              " ['Rodney Atkins', ['White']],\n",
              " ['Roman GianArthur', ['Black or African American']],\n",
              " ['Roscoe Dash', ['Black or African American']],\n",
              " ['Rozes', ['White']],\n",
              " ['Ruth B', ['White']],\n",
              " ['Ryan Lewis', ['White']],\n",
              " ['Ryan Tedder', ['White']],\n",
              " ['Sabi', ['Black or African American', 'American Indian or Alaska Native']],\n",
              " ['Sage the Gemini', ['Black or African American']],\n",
              " ['Sam Hunt', ['White']],\n",
              " ['Sam Smith', ['White']],\n",
              " ['Sara Bareilles', ['White']],\n",
              " ['Saweetie', ['Black or African American', 'Asian']],\n",
              " ['ScHoolboy Q', ['Black or African American']],\n",
              " ['Sean Kingston', ['Black or African American']],\n",
              " ['Sean Paul', ['Black or African American', 'White']],\n",
              " ['Selena Gomez', ['American Indian or Alaska Native', 'White']],\n",
              " ['Shaed', ['White']],\n",
              " ['Shakira', ['White']],\n",
              " ['Shawn Mendes', ['White']],\n",
              " ['Shay', ['White']],\n",
              " ['Sheck Wes', ['Black or African American']],\n",
              " ['Shontelle', ['Black or African American']],\n",
              " ['Sia', ['White']],\n",
              " ['Silent', ['Unknown']],\n",
              " ['Skip Marley', ['Black or African American', 'White']],\n",
              " ['Skrillex', ['White']],\n",
              " ['Skylar Grey', ['White']],\n",
              " ['Snoop Dogg', ['Black or African American']],\n",
              " ['Snow', ['White']],\n",
              " ['Social House', ['White']],\n",
              " ['Sons', ['White']],\n",
              " ['Sugarland', ['White']],\n",
              " ['Swae Lee', ['Black or African American']],\n",
              " ['Swedish House Mafia', ['White']],\n",
              " ['SZA', ['Black or African American']],\n",
              " ['Taio Cruz', ['Black or African American']],\n",
              " ['Taylor Swift', ['White']],\n",
              " ['Teo', ['Black or African American']],\n",
              " ['The Band Perry', ['White']],\n",
              " ['The Black Eyed Peas', ['Black or African American', 'White']],\n",
              " ['The Cataracs', ['White']],\n",
              " ['The Chainsmokers', ['White']],\n",
              " ['The Lumineers', ['White']],\n",
              " ['The Neighbourhood', ['White']],\n",
              " ['the Scene', ['White']],\n",
              " ['The Script', ['White']],\n",
              " ['The Throne', ['White']],\n",
              " ['The Wanted', ['White']],\n",
              " ['The Weeknd', ['Black or African American']],\n",
              " ['Thomas Rhett', ['White']],\n",
              " ['Thompson Square', ['White']],\n",
              " ['T.I.', ['Black or African American']],\n",
              " ['Tiara Thomas', ['Black or African American']],\n",
              " ['Timbaland', ['Black or African American']],\n",
              " ['Tim McGraw', ['White']],\n",
              " ['Tinashe', ['Black or African American', 'White']],\n",
              " ['Tinie Tempah', ['Black or African American']],\n",
              " ['Toby Keith', ['White']],\n",
              " ['Tory Lanez',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'White']],\n",
              " ['Tove Lo', ['White']],\n",
              " ['T-Pain', ['Black or African American']],\n",
              " ['Train', ['White']],\n",
              " ['Travie McCoy',\n",
              "  ['Black or African American', 'American Indian or Alaska Native', 'White']],\n",
              " ['Travis Scott', ['Black or African American']],\n",
              " ['Trey Songz', ['Black or African American']],\n",
              " ['T-Wayne', ['Black or African American']],\n",
              " ['Twenty One Pilots', ['White']],\n",
              " ['Ty Dolla Sign', ['Black or African American']],\n",
              " ['Tyga', ['Black or African American']],\n",
              " ['Uncle Kracker', ['White']],\n",
              " ['Usher', ['Black or African American']],\n",
              " ['Vance Joy', ['White']],\n",
              " ['Vika Jigulina', ['White']],\n",
              " ['Vinz', ['Black or African American']],\n",
              " ['Waka Flocka Flame', ['Black or African American']],\n",
              " ['Wale', ['Black or African American']],\n",
              " ['Walk the Moon', ['White']],\n",
              " ['Wanz', ['Black or African American']],\n",
              " ['will.i.am', ['Black or African American']],\n",
              " ['Willy William', ['Black or African American']],\n",
              " ['Wiz Khalifa', ['Black or African American']],\n",
              " ['Wizkid', ['Black or African American']],\n",
              " ['X Ambassadors', ['White']],\n",
              " ['XXXTentacion', ['Black or African American']],\n",
              " ['YFN Lucci', ['Black or African American']],\n",
              " ['YG', ['Black or African American']],\n",
              " ['YK Osiris', ['Black or African American']],\n",
              " ['Ylvis', ['White']],\n",
              " ['YNW Melly', ['Black or African American']],\n",
              " ['Yo Gotti', ['Black or African American']],\n",
              " ['YoungBoy Never Broke Again', ['Black or African American']],\n",
              " ['Young Dolph', ['Black or African American']],\n",
              " ['Young Money', ['Black or African American']],\n",
              " ['Young Thug', ['Black or African American']],\n",
              " ['Zacari', ['Black or African American']],\n",
              " ['Zac Brown Band', ['White']],\n",
              " ['Zara Larsson', ['White']],\n",
              " ['Zay Hilfigerrr', ['Black or African American']],\n",
              " ['Zayion McCall', ['Black or African American']],\n",
              " ['Zayn', ['Asian', 'White']],\n",
              " ['Zedd', ['White']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    }
  ]
}